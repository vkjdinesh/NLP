{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKYqMH/Q1ojxpub9raGp7w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjdinesh/NLP/blob/main/Test_March23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change  the run time to GPU"
      ],
      "metadata": {
        "id": "l3jbz0B5mRZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqmwvR06lZL_"
      },
      "outputs": [],
      "source": [
        "!pip install Pillow==10.1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
        "!pip install huggingface_hub\n",
        "!pip install llama-cpp-python==0.1.78\n",
        "!pip install numpy==1.23.4\n",
        "!pip install Flask==3.0.0\n",
        "!pip install flask-ngrok==0.0.25\n",
        "!pip install nltk==3.8.1\n",
        "!pip install diffusers==0.11.1\n",
        "!pip install transformers scipy ftfy accelerate"
      ],
      "metadata": {
        "id": "vCR_jCQblaGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here please include your ngrok authentication token."
      ],
      "metadata": {
        "id": "T-dGa_PNlgm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.ngrok2/\n",
        "!echo -e \"version: '2'\\nregion: jp\\nauthtoken: 2AxYhubJCLtqHpl4wB9pgrvl9Gl_64EcqFrwYmasY1zq86SMj\" > ~/.ngrok2/ngrok.yml"
      ],
      "metadata": {
        "id": "SIEO_jmNlb38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format"
      ],
      "metadata": {
        "id": "g0onQ37cload"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ],
      "metadata": {
        "id": "KI4bi_tTlrhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "lcpp_llm = None\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU cores\n",
        "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
        "    )"
      ],
      "metadata": {
        "id": "4h93azO8lttV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
        "#float value you can update it to 32 if there is any error popup\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "K_jKgksklwcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Flask-Cors==4.0.0\n"
      ],
      "metadata": {
        "id": "Jt_JjPRSl33M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, send_file\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import matplotlib.pyplot as plt\n",
        "import io"
      ],
      "metadata": {
        "id": "PAs9b0zhl77X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS\n",
        "\n",
        "import nltk\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "html = \"\"\"\n",
        "<html lang=\"en\">\n",
        "  <head>\n",
        "    <meta charset=\"UTF-8\" />\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "    <style>\n",
        "      :root {\n",
        "        --clr-green: #a3e635;\n",
        "        --clr-dark-blue: #172554;\n",
        "        --clr-white: #f8fafc;\n",
        "      }\n",
        "\n",
        "      * {\n",
        "        padding: 0;\n",
        "        margin: 0;\n",
        "        font-family: \"Franklin Gothic Medium\", \"Arial Narrow\", Arial, sans-serif;\n",
        "        border-radius: 0px;\n",
        "      }\n",
        "\n",
        "      body {\n",
        "        background-color: var(--clr-dark-blue);\n",
        "      }\n",
        "\n",
        "      .section {\n",
        "        height: 100%;\n",
        "      }\n",
        "\n",
        "      .prompt {\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "        gap: 50px;\n",
        "      }\n",
        "\n",
        "      .btn {\n",
        "        width: 200px;\n",
        "        height: 50px;\n",
        "        border: none;\n",
        "      }\n",
        "\n",
        "      .prompt__title {\n",
        "        color: var(--clr-green);\n",
        "        font-size: 100px;\n",
        "      }\n",
        "\n",
        "      .prompt__textfield {\n",
        "        width: 600px;\n",
        "        height: 70px;\n",
        "        padding: 10px;\n",
        "        text-align: center;\n",
        "        background-color: var(--clr-green);\n",
        "        border: none;\n",
        "      }\n",
        "\n",
        "      .story {\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "        gap: 70px;\n",
        "        color: var(--clr-white);\n",
        "        margin: auto 70px;\n",
        "      }\n",
        "\n",
        "      .story__story {\n",
        "        width: 600px;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: start;\n",
        "        gap: 20px;\n",
        "      }\n",
        "\n",
        "      .story__story-title {\n",
        "        text-align: center;\n",
        "        font-size: 60px;\n",
        "      }\n",
        "\n",
        "      .story__story-line {\n",
        "        width: 100%;\n",
        "        height: 5px;\n",
        "        background-color: var(--clr-green);\n",
        "      }\n",
        "\n",
        "      .sentence {\n",
        "        font-size: 20px;\n",
        "      }\n",
        "\n",
        "      .sentence:hover {\n",
        "        background-color: var(--clr-green);\n",
        "        cursor: pointer;\n",
        "      }\n",
        "\n",
        "      .story__image {\n",
        "        width: 600px;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: start;\n",
        "        align-items: center;\n",
        "        gap: 20px;\n",
        "      }\n",
        "\n",
        "      .story__image-title {\n",
        "        font-size: 40px;\n",
        "      }\n",
        "\n",
        "      .box {\n",
        "        height: 50px;\n",
        "        width: 100%;\n",
        "        color: black;\n",
        "        text-align: center;\n",
        "        background-color: var(--clr-green);\n",
        "      }\n",
        "\n",
        "      .story__image-img {\n",
        "        width: 100%;\n",
        "      }\n",
        "\n",
        "      .mcq {\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        align-items: center;\n",
        "        gap: 20px;\n",
        "      }\n",
        "\n",
        "      .mcq__title {\n",
        "        font-size: 40px;\n",
        "        color: white;\n",
        "      }\n",
        "\n",
        "      .mcq__line {\n",
        "        width: 50%;\n",
        "        height: 5px;\n",
        "        background-color: var(--clr-green);\n",
        "      }\n",
        "\n",
        "      .mcq__text {\n",
        "        font-size: 20px;\n",
        "        width: 50%;\n",
        "        color: white;\n",
        "      }\n",
        "    </style>\n",
        "    <title>AI Web App</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <div class=\"section prompt\">\n",
        "      <h1 class=\"prompt__title\">Enter the Text prompt.</h1>\n",
        "      <form>\n",
        "        <input\n",
        "          class=\"prompt__textfield\"\n",
        "          type=\"text\"\n",
        "          name=\"prompt\"\n",
        "          placeholder=\"Two dogs playing together on a beach\"\n",
        "        />\n",
        "      </form>\n",
        "      <button class=\"btn\" onclick=\"submit()\">Enter</button>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section story\">\n",
        "      <div class=\"story__story\">\n",
        "        <h1 class=\"story__story-title\">Short Story</h1>\n",
        "        <div class=\"story__story-line\"></div>\n",
        "        <div class=\"story__story-text\"></div>\n",
        "      </div>\n",
        "      <div class=\"story__image\">\n",
        "        <h1 class=\"story__image-title\">Image</h1>\n",
        "        <div>\n",
        "          <div class=\"box\">\n",
        "            Max and Bella, two inseparable dogs, were playing joyfully on a\n",
        "            sun-kissed beach.\n",
        "          </div>\n",
        "          <img\n",
        "            class=\"story__image-img\"\n",
        "            src=\"https://png.pngtree.com/thumb_back/fw800/background/20220111/pngtree-fighting-dogs-on-the-beach-two-angry-sociability-photo-image_26163740.jpg\"\n",
        "            alt=\"generated picture\"\n",
        "          />\n",
        "        </div>\n",
        "        <button class=\"btn\" onclick=\"showMcq()\">MCQ</button>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section mcq\">\n",
        "      <h1 class=\"mcq__title\">MCQs</h1>\n",
        "      <div class=\"mcq__line\"></div>\n",
        "      <div class=\"mcq__text\"></div>\n",
        "    </div>\n",
        "\n",
        "    <script src=\"https://code.jquery.com/jquery-3.7.1.min.js\" integrity=\"sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=\" crossorigin=\"anonymous\"></script>\n",
        "    <script>\n",
        "        function submit() {\n",
        "            console.log(\"hit js\")\n",
        "            let prompt = document.querySelector(\".prompt__textfield\").value;\n",
        "            console.log(prompt);\n",
        "            $.ajax({\n",
        "                url: '/handle_prompt',\n",
        "                type: 'POST',\n",
        "                data: {prompt: prompt},\n",
        "                success: function(response) {\n",
        "                    story = response.result[0];\n",
        "                    alert(story);\n",
        "                    let div = document.querySelector(\".story__story-text\");\n",
        "                    div.textContent = \"\";\n",
        "                    story.forEach((sentence, x) => {\n",
        "                        let p = document.createElement(\"p\");\n",
        "                        let br = document.createElement(\"br\");\n",
        "\n",
        "                        p.textContent = sentence;\n",
        "                        p.classList.add(\"sentence\");\n",
        "                        p.onclick = getImage;\n",
        "\n",
        "                        div.appendChild(p);\n",
        "                        div.appendChild(br);\n",
        "                    })\n",
        "\n",
        "                    let storySection = document.querySelector(\".story\");\n",
        "                    storySection.scrollIntoView({ behavior: \"smooth\" });\n",
        "                    console.log(\"done creating sentences\");\n",
        "\n",
        "                    mcq = response.result[1];\n",
        "                    div = document.querySelector(\".mcq__text\");\n",
        "                    mcq.forEach((mcqq, x) => {\n",
        "                        let p = document.createElement(\"p\");\n",
        "\n",
        "                        p.textContent = mcqq;\n",
        "\n",
        "                        div.appendChild(p);\n",
        "                    })\n",
        "                },\n",
        "                error: function(error) {\n",
        "                    console.log(\"error from ajax: \" + JSON.stringify(error));\n",
        "                }\n",
        "            });\n",
        "        }\n",
        "\n",
        "        function getImage(event) {\n",
        "            let ele = event.target\n",
        "            console.log(ele.innerHTML)\n",
        "            let img = document.querySelector(\".story__image-img\");\n",
        "            img.src = \"/handle_image/\" + ele.innerHTML;\n",
        "\n",
        "            let caption = document.querySelector(\".box\");\n",
        "            caption.innerHTML = ele.innerHTML;\n",
        "\n",
        "            console.log(\"changed image\")\n",
        "          }\n",
        "\n",
        "        function showMcq() {\n",
        "          let mcqSection = document.querySelector(\".mcq\");\n",
        "          mcqSection.scrollIntoView({ behavior: \"smooth\" });\n",
        "        }\n",
        "    </script>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route('/handle_prompt', methods=['POST'])\n",
        "def handle_prompt():\n",
        "    print('hit py')\n",
        "    prompt = request.form.get('prompt')\n",
        "    prompt_template = f'''\n",
        "    USER: {prompt + \"1.give short story with 200 words. 2. generate 5 MCQs with options and answer\"}\n",
        "\n",
        "    ASSISTANT:\n",
        "    '''\n",
        "    response = lcpp_llm(prompt=prompt_template, max_tokens=1500, temperature=0.5, top_p=0.95,\n",
        "                        repeat_penalty=1.2, top_k=150,\n",
        "                        echo=True)\n",
        "\n",
        "    res = response[\"choices\"][0][\"text\"]\n",
        "    res = res.split(prompt_template)[1] # getting only the AI's response\n",
        "    print(res)\n",
        "\n",
        "    try:\n",
        "        story, mcq = res.split(\"1.\")\n",
        "    except ValueError:\n",
        "        story, mcq = res.split(\"1)\")\n",
        "\n",
        "    if story.count(\":\") == 2:\n",
        "        story = story.split(\":\")[1].strip()\n",
        "    elif story.count(\":\") == 3:\n",
        "        story = story.split(\":\")[2].strip()\n",
        "    elif story.count(\":\") == 5:\n",
        "        story = story.split(\":\")[5].strip()\n",
        "\n",
        "    mcq = \"1.\" + mcq\n",
        "\n",
        "    nltk.download('punkt')\n",
        "    story = nltk.sent_tokenize(story)\n",
        "    mcq = nltk.sent_tokenize(mcq)\n",
        "    story = story[:-1] # exclude the last sentence\n",
        "\n",
        "    print(story, mcq)\n",
        "    return jsonify(result=[story, mcq])\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/handle_image/<prompt>', methods=['GET'])\n",
        "def handle_image(prompt):\n",
        "    try:\n",
        "        print('hit py')\n",
        "\n",
        "        # Generate image using the GPT-Neo pipeline\n",
        "        image = pipe(prompt + \" Japanese Anime\").images[0]\n",
        "\n",
        "        # Save the generated image temporarily\n",
        "        image.save(\"output_image.jpeg\")\n",
        "\n",
        "        # Open the image using PIL and convert to BytesIO\n",
        "        with open(\"output_image.jpeg\", \"rb\") as image_file:\n",
        "            image_io = io.BytesIO(image_file.read())\n",
        "\n",
        "        # Remove the temporary image file\n",
        "        os.remove(\"output_image.jpeg\")\n",
        "\n",
        "        # Return the processed image\n",
        "        return send_file(image_io, mimetype='image/jpeg')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return jsonify({'error': str(e)})\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return html\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "7hYx1e0AmAr3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}